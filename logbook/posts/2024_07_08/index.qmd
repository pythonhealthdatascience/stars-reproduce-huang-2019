---
title: "Day 4"
author: "Amy Heather"
date: "2024-07-08"
categories: [reproduce]
bibliography: ../../../quarto_site/references.bib
---

## 09.14-09.17, 09.22-09.24, 09.30-09.35: Continuing on in-text results 1 and 2

Re-ran twice more to see again how much variation we get between runs, and how likely that could attribute for the difference against the paper. We saw-

| Output | Result 1 (Day 3) | Result 2 (Day 3) | Result 3 (Today) | Result 4 (Today) | Paper |
| --- | --- | --- | --- | --- | --- |
| Baseline | 13.33 minutes | 13.65 minutes | 14.15 minutes | 14.09 minutes | - |
| Exclusive | 8.58 minutes (4.75 reduction) | 9.20 minutes (4.45 reduction) | 8.79 minutes (5.36 reduction) | 8.05 minutes (6.04 reduction) | 6 minute reduction from baseline |
| Two AngioINR | 14.86 minutes (1.53 increase) | 13.61 minutes (0.04 reduction) | 14.37 minutes (0.22 increase) | 14.04 minutes (0.05 reduction) | 4 minute reduction from baseline |

Based on this, it's reasonable to assume that a 6 minute reduction can be observed within the variation of model runs (in-text result 1), but that the two angioINR scenario is not matching up.

::: {.callout-tip}
## Reflections

Environment used does not match up to paper - paper use Simmer version 4.1.0, and otherwise, other versions of packages and of R being used are more recent than publication. It is unlikely that differences in results are due to this (although not impossible). Note trying to revert the environment to older versions as a possible troubleshooting strategy if issues persist, but not yet, due to major challenges found in trying to do so prior.
:::

## 09.50-10.49, 11.02-11.05, 11.13-11.14: Adding seeds

Based on [this tutorial](https://pythonhealthdatascience.github.io/stars-treat-simmer/02_model/03_r_sampling.html), add seeds to the model. This is because the result was only returned by certain runs of the model and not others, so want to add seeds now so can give a seed for which the result is reproduced. I installed simEd - `renv::install("simEd")` and add to `DESCRIPTION` and `renv::snapshot()` - and then made the following changes to the model:

* `library(simEd)`
* Input `seed` to function which becomes SEED, then `set.seed(SEED+i)` within model replications
* Sampling functions changed from `r` to `v` - i.e. `rpois()` to `vpois()`, with incremental stream numbers

I tried running baseline, but it took a long time - after 6 minutes, it was still running (which is normally how long the whole script takes). I interrupted it and it returned `Error : object 'shifts' not found`. However, no change has been made to shifts code. I ran a short section of code practicing sampling and this worked fine:

```
library(simEd)

ed_pt = 107000
year2min = 525600
I_ED  = round(year2min/ed_pt)

set.seed(5)
vpois(10, I_ED, stream=1)

set.seed(3)
vpois(10, I_ED, stream=1)

set.seed(5)
vpois(10, I_ED, stream=1)
```

I then tried running it with 3 replications instead of 30 (`baseline <- run_model(nsim=3, seed=100)`), and that ran fine, so it appears that introducing this library just slowed down the model alot, as 3 replications could complete in 40 seconds.

I looked into changing the `lapply()` in `model.R` to a parallel version:

* `parLapply` requires you to specify every variable to be included, plus additional lines of code to set up and close clusters
* `mcapply()` just requires you to change `lapply`

Hence, I tried `mcapply`, but it returned `Error: external pointer is not valid`, which was resolved based on [this post](https://groups.google.com/g/simmer-devel/c/4cQWtS571iQ?pli=1) by adding `wrap()`. However, learnt that mclapply wouldn't work on Windows. Moreover, it still took a fair while to run (testing with 30 replications, it's still going at 4 minutes).

As such, removed simEd from `model.R` and environment and returned to `rpois()`, and instead just set a simple seed without controlling streams. The time for this to run was as per usual, which was fab. I ran the baseline model twice with the same seed and compared the results, and it came out looking (by eye, at the processed results) identical.

I therefore ran baseline and exclusive with three different starter seeds, and the seed `200` came out closest to the paper -

* Baseline: 13.96 minutes
* Exclusive: 8.12 minutes
* Difference: 5.84 minutes

Hence, I feel we can mark in-text result 1 as reproduced at this time (11.14), with starter seed of 200.

```{python}
# Add timings for this result
```

### 11.15-12.30, 13:15-13.50, 13.55-X: Figure 2

Figure 2 uses the results from the scenarios above but creates plots where:

* X axis is wait time in minutes (on a non-linear scale)
* Y axis is standardised density of patients in queue, from 0 to 1 (on a non-linear scale)
  * i.e. "Probability density of patients who are waiting standardised to patients who are not waiting"
  * i.e. "To facilitate graphical and descriptive comparison across models, we express waiting times as relative probabilities of waiting a given amount of time, compared to not waiting at all. Since most patients accessed services without waiting, wait time densities could be directly compared across simulations after this normalization."

It's not immediately clear exactly what this means, but I'll start with creating a density plot of waiting times for one of the resources. First though, I add some code to save the model results to CSV files so that we don't have to re-run the model each time (since with seeds added, it should now come out the same each time anyway). I initially saved these with `write.csv()` but it was too slow, so then (based on [this tutorial](https://medium.com/r-evolution/how-to-export-100x-faster-csv-files-from-r-for-big-data-1d969a6b9269)), I switched to `data.table::fwrite()` ("fast CSV writer"), which was much much better! Hence, used `fread()` to import (as should also be quicker, based on [this tutorial](https://www.r-bloggers.com/2020/09/the-fastest-way-to-read-and-writes-file-in-r/)).

I then created a basic density plot with ggplot with ED AngioINR untransformed wait times.

```
base_angio <- res_base %>% filter(category == "ed") %>% filter(resource == "angio_inr")
p <- ggplot(base_angio, aes(x = wait_time)) +
  geom_density()
ggsave(path_fig2a)
p
```

![Figure 2A raw wait times](fig2a_example1.png)

### Y axis

I played around with various transformations, as it wasn't immediately clear to me how they had stretched the y axis, including creating custom functions, transforming the data directly, and trying out default transform options. I eventually stumbled across `scale_y_continuous(transform="sqrt")`, which matched up to the axis in the paper.

### Standardising the density

I played around with a few different transformation as I tried to work out what they meant by standardised density of patients in queue. Whilst converting raw wait times to probabilities, I noticed a bunch of ever so slightly negative wait times, but given these are very small (i.e. 0.0000000...), I am not concerned.

One thing I tried was converting each wait time into a probability of that wait time (e.g. rounding each to 2dp, then 0 wait time = probability 0.68).

```
# Filter to just AngioINR for ED and round wait times to 2dp
base_angio <- res_base %>%
  filter(category == "ed", resource == "angio_inr") %>%
  select(wait_time)

# Round to 2dp
base_angio$wait_time <- round(base_angio$wait_time, 2)

# Convert raw wait times into probability of waiting that long given all
# wait times observed
prob_wait <- base_angio %>%
  group_by(wait_time) %>%
  summarise(count = n()) %>%
  mutate(probability = count / sum(count)) %>%
  select(wait_time, probability)

ggplot(prob_wait, aes(x=wait_time, y=probability)) + geom_line() + geom_point()
```

However, that really didn't look quite right.

![Figure 2A wrong transformation](fig2a_example2.png)

Looking at the curve with the raw wait times, the shape of the curve is more similar to the paper, just with different y axis and stretched. Revisiting the paper description, it is the "relative probabilities of waiting a given amount of time, compared to not waiting at all". So, it's not just the relative probability of waiting a given amount of time, compared to any other time.

I created a plot where the waiting times were normalised in such a way that the values range from 0 to 1, which starts to look a bit more similar to the paper -

```
# Filter to just AngioINR for ED and round wait times to 2dp
base_angio <- res_base %>%
  filter(category == "ed", resource == "angio_inr")

# Set negative wait times to 0
base_angio$wait_time[base_angio$wait_time < 0] <- 0

# Create the density data
density_data <- density(base_angio$wait_time)

# Normalize the density values
normalized_density <- density_data$y / max(density_data$y)

# Create a data frame with the normalized density values
density_df <- data.frame(x = density_data$x, y = normalized_density)

# Plot using ggplot2
ggplot(density_df, aes(x = x, y = y)) +
  geom_line() +
  scale_y_continuous(transform="sqrt")
ggsave(path_fig2a)
```

![Figure 2A scaled to 0 to 1](fig2a_example3.png)
