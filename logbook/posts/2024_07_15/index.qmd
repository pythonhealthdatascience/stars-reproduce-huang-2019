---
title: "Day 9"
author: "Amy Heather"
date: "2024-07-15"
categories: [guidelines, compendium]
bibliography: ../../../quarto_site/references.bib
---

::: {.callout-note}

Consensus on evaluation + reflections + research compendium. Total evaluation time: 1h 45m.

:::

## 08.22-08.30, 08.37-08.41, 10.53-10.55: Consensus on evaluation

Pulled together to share with Tom and Alison, to get a second opinion on these, and emailed over a link. Later, input responses below. Agreed with all decisions, so no changes required.

**Badges**:

* <https://pythonhealthdatascience.github.io/stars-reproduce-huang-2019/evaluation/badges.html>
* No uncertainties
* 9 unmet criteria

**STARS framework**:

* <https://pythonhealthdatascience.github.io/stars-reproduce-huang-2019/evaluation/artefacts.html>
* No uncertainities
* 9 unmet criteria

**Reporting guidelines**:

* <https://pythonhealthdatascience.github.io/stars-reproduce-huang-2019/evaluation/reporting.html>
* Five uncertainities as below.
* 4 + 7 unmet criteria

| Item | My comments | Thoughts from Tom |
| --- | --- | --- |
| STRESS-DES 1.2 Model outputs. Define all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated. | It does describe the measures, and how these are calculated, and so I have said it met these criteria, although I did find it hard to understand/calculate the relative probability of waiting, and would've benefited from further detail/equations. Currently marked as fully met. | Agree with decision. |
| STRESS-DES 1.3 Experimentation aims. If the model has been used for experimentation, state the objectives that it was used to investigate. (A) Scenario based analysis ‚Äì Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed. | I feel the paper does describe the scenarios clearly - my only hesitation is that I have been unable to successfully implement the exclusive use scenario - but that feels like a coding issue rather than a description issue? As, on the face of it, the article describes everything I need to know. Currently marked as fully met. | Agree with decision. Argue that description in article is a reasonable explanation of the logic in play - "First, in the ‚Äúexclusive-use‚Äù scenario, angioINR is not available for elective IR patients. Its use is restricted to stroke, elective INR and emergency IR patients"" @huang_optimizing_2019 |
| STRESS-DES 3.2 Pre-processing. Provide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers. | None provided, so presumed not applicable - but hard to say, as maybe there was pre-processing that simply wasn't mentioned. But as not possible to know either way, assumed not-applicable | Agree with decision. Give benefit of the doubt by its absence - although ideally they would state no data pre-processing was used. |
| ISPOR SDM 12 Is cross validation performed and reported | Wasn't certain whether to mark this is unmet (‚ùå) or not applicable (N/A)? Currently set as unmet.<br><br>Evidence - stating there is a gap in the `Introduction`: "In contrast to other healthcare fields, a resource-use optimization model has not been implemented for comprehensive stroke services." @huang_optimizing_2019 | Agree with decision. |
| ISPOR SDM 15 Is the model generalizability issue discussed? | Not sure if it is partially (üü°) or fully met (‚úÖ)? Currently marked as fully.<br><br>Evidence - `Discussion`: "The quality of the ECR service appears to be robust to important parameters, such as the number of radiologists. The simulation findings apply to ECR services that can be represented by the model in this study. As such, utilization of this model to its maximum capacity requires tailoring the model to local needs, as institutional bottlenecks differ between providers. We specifically developed this model using an open source programming language so that the source code can serve as a basis for future model refinement and modification."<br><br>@huang_optimizing_2019 | Agree with decision. |

## Timings for evaluation

```{python, python.reticulate = FALSE}
import sys
sys.path.append('../')
from timings import calculate_times

# Minutes used prior to today
used_to_date = 91

# Times from today
times = [
    ('08.22', '08.30'),
    ('08.37', '08.41'),
    ('10.53', '10.55')]

calculate_times(used_to_date, times, limit=False)
```

## Untimed: Revisiting R dependency management options

Did some further research into options for dependency management in R.

## Untimed: Recording troubleshooting and reflections

Completed `reflections`.qmd.

## Untimed: Revisiting GitHub actions issues

Tried forking and running actions from existing repositories that render and publish an R-based Quarto book on GitHub pages.

* <https://github.com/ddotta/cookbook-rpolars> - build failed due to unexpected value to function in one of the .qmd files
* <https://github.com/b-rodrigues/rap4all> - add workflow_dispatch to action and ran it but it failed as no gh-pages branch. Hence, copied that also (which successfully deployed) and ran the action again. This worked! Hurrah! üòÅ

Then updated my action to be similar to the `rap4all` actions and tried it. This failed - "configuration failed because libcurl was not found". I add installation of libcurl and ran it again, but this all failed just like before, with the error `there is no package called 'rmarkdown'`.

## Untimed: Research compendium

Some further work on the research compendium stage.

* Add `testthat` to environment
* Wrote basic test but to run it, RStudio had prompt that it required update of devtools. Selected "yes" and then saved another `renv::snapshot()` once it completed. However, I cancelled it as realised could run without devtools (and devtools would be alot of extra dependencies!)
* Ran test with `testthat::test_dir("tests")`

Links:

* Another good resource for tests in R: <https://raps-with-r.dev/testing.html>
* A good resource for Docker and R: <https://raps-with-r.dev/repro_cont.html>
* Tom's R dockerfile: <https://github.com/TomMonks/reproducible_r_docker/blob/main/Dockerfile>
